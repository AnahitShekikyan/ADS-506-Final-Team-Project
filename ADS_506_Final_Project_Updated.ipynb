{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyORzB77fkj/r4qhjEmt/v6K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnahitShekikyan/ADS-506-Final-Team-Project/blob/main/ADS_506_Final_Project_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bike Sharing Dataset**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5MdY1E51iUvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Data & Libraries**"
      ],
      "metadata": {
        "id": "Ut_FmH2Uif5w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCwDtyGliKio"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "!pip install pmdarima\n",
        "import pmdarima as pm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_day = pd.read_csv('/content/drive/MyDrive/day.csv')\n",
        "df_hour = pd.read_csv('/content/drive/MyDrive/hour.csv')"
      ],
      "metadata": {
        "id": "ye6kL6YXinkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic Data Information**"
      ],
      "metadata": {
        "id": "0Z5h-mdxirfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# printing information about data\n",
        "df_day.info()\n",
        "df_hour.info()"
      ],
      "metadata": {
        "id": "NLtEKnPfiquR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for duplicates\n",
        "df_day.duplicated().sum()\n",
        "df_hour.duplicated().sum()"
      ],
      "metadata": {
        "id": "lnWERb6ki5mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing basic describtion about day and hour datasets\n",
        "df_day.describe()\n",
        "df_hour.describe()"
      ],
      "metadata": {
        "id": "MmLaUDYUi9_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting date to numeric\n",
        "df_day['dteday'] = pd.to_datetime(df_day['dteday'])\n",
        "df_hour['dteday'] = pd.to_datetime(df_hour['dteday'])\n",
        "\n",
        "# adding new features like day of the year\n",
        "df_hour['day_of_year'] = df_hour['dteday'].dt.dayofyear"
      ],
      "metadata": {
        "id": "tAUKYBHNjAwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Visualization and Distribution Analysis**"
      ],
      "metadata": {
        "id": "lLObxwnLjFKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of histogram of the \"cnt\" variable (overall pattern of bike usage)\n",
        "sns.histplot(df_hour['cnt'], kde=True)\n",
        "plt.title(\"Distribution of Bike Rentals\")\n",
        "plt.xlabel(\"Count of Bike Rentals\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6BiTdcnajEG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplot of temperature, weather, and bike rentals\n",
        "sns.scatterplot(data=df_day, x='temp', y='cnt', hue='weathersit')\n",
        "plt.title(\"Temperature vs. Bike Rentals\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Count of Bike Rentals\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lZls9Gr6jO1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlation Analysis**"
      ],
      "metadata": {
        "id": "pCuk7Kd-jUC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the correlation matrix\n",
        "corr = df_hour.drop(columns=['dteday']).corr()\n",
        "\n",
        "# Creating a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Creating the heatmap with the mask\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr, mask=mask, annot=True, cmap='coolwarm', annot_kws={\"size\": 8})\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.title('Triangular Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9qOVzYuUjRB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Temporal Analysis**"
      ],
      "metadata": {
        "id": "ZjITzHMWjbuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# showing how the number of rentals varies throughout the day by aggregating the \"cnt\" by the \"hr\" column\n",
        "sns.lineplot(data=df_hour.groupby('hr')['cnt'].sum().reset_index(), x='hr', y='cnt', marker='o') #Applying sum() before reset_index()\n",
        "plt.title('Average Bike Rentals by Hour')\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Average Count of Rentals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8KvfHGFqjZ8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating monthly trends for the seasonal effects\n",
        "monthly_trend = df_hour.groupby('mnth')['cnt'].mean().reset_index()\n",
        "sns.lineplot(x='mnth', y='cnt', data=monthly_trend, marker='o')\n",
        "plt.title('Average Bike Rentals by Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Count of Rentals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0a2VYfEHjiJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Categorical Feature Analysis**"
      ],
      "metadata": {
        "id": "1zzCzN7JjpRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bike rentals across different seasons (\"season\") or weather situations (\"weathersit\")\n",
        "sns.boxplot(x='season', y='cnt', data=df_day, palette='viridis')\n",
        "plt.title('Bike Rentals by Season')\n",
        "plt.xlabel('Season (1=Spring, 2=Summer, 3=Fall, 4=Winter)')\n",
        "plt.ylabel('Count of Rentals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7nEo6itBjmqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the average rentals during holidays (holiday == 1) vs non-holidays\n",
        "sns.boxplot(x='holiday', y='cnt', data=df_day)\n",
        "plt.title('Bike Rentals: Holiday vs Non-Holiday')\n",
        "plt.xlabel('Holiday')\n",
        "plt.ylabel('Count of Rentals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jbzvc5Hyjyls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Seasonality Decomposition**"
      ],
      "metadata": {
        "id": "Q_nL_h-Wj2f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Useing seasonal decomposition to break down the time series into trend, seasonal, and residual components\n",
        "\n",
        "result = seasonal_decompose(df_day['cnt'], model='additive', period=12)\n",
        "result.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sIJQ14i0j4bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Outlier Detection**"
      ],
      "metadata": {
        "id": "6gEpJlsXj-zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# detect any anomalies in the dataset\n",
        "sns.boxplot(data=df_hour[['temp', 'hum', 'windspeed', 'cnt']])\n",
        "plt.title('Outlier Detection in Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EMNFoPKnjw29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing extreme outliers (values beyond 3 times the IQR)\n",
        "Q1 = df_day['cnt'].quantile(0.25)\n",
        "Q3 = df_day['cnt'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "df_day_no_outliers = df_day[(df_day['cnt'] >= (Q1 - 3 * IQR)) & (df_day['cnt'] <= (Q3 + 3 * IQR))]"
      ],
      "metadata": {
        "id": "nctV6AbTkWFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring Feature Relationships\n",
        "sns.pairplot(df_hour[['temp', 'atemp', 'hum', 'windspeed', 'cnt']])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HCxVUxT4kcSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering Ideas**"
      ],
      "metadata": {
        "id": "VJiDGtzYkhVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date columns to datetime\n",
        "df_day['dteday'] = pd.to_datetime(df_day['dteday'])\n",
        "df_hour['dteday'] = pd.to_datetime(df_hour['dteday'])"
      ],
      "metadata": {
        "id": "c9bXBKw5kets"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "train_size = int(len(df_day) * 0.8)  # 80% training data\n",
        "train, test = df_day.iloc[:train_size], df_day.iloc[train_size:]"
      ],
      "metadata": {
        "id": "i3bDvkVkkyAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting date index for time series compatibility\n",
        "train.set_index('dteday', inplace=True)\n",
        "test.set_index('dteday', inplace=True)"
      ],
      "metadata": {
        "id": "XxesWbcgk0nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Metrics and Evalulations**"
      ],
      "metadata": {
        "id": "jEuC3FnLk3RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stationarity Test (ADF Test)\n",
        "adf_test = adfuller(df_day['cnt'])\n",
        "print(f\"ADF Statistic: {adf_test[0]}\")\n",
        "print(f\"p-value: {adf_test[1]}\")\n",
        "print(f\"Critical Values: {adf_test[4]}\")"
      ],
      "metadata": {
        "id": "wxcAUztSk2tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Differencing if Non-Stationary\n",
        "df_day['cnt_diff'] = df_day['cnt'].diff().dropna()\n",
        "plt.plot(df_day['cnt_diff'])\n",
        "plt.title(\"Differenced Bike Rentals Time Series\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vU-_BEiolU-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Walk Baseline\n",
        "test['random_walk'] = train['cnt'].iloc[-1]\n",
        "rmse_rw = np.sqrt(mean_squared_error(test['cnt'], test['random_walk']))\n",
        "mae_rw = mean_absolute_error(test['cnt'], test['random_walk'])\n",
        "\n",
        "print(f\"Random Walk RMSE: {rmse_rw:.2f}, MAE: {mae_rw:.2f}\")"
      ],
      "metadata": {
        "id": "y45S_k8tsq70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['forecast'] = train['cnt'].iloc[-1]\n",
        "\n",
        "# Assuming 'test' DataFrame contains 'cnt' (actual) and 'forecast' (predicted) values\n",
        "residuals = test['cnt'] - test['forecast']\n",
        "\n",
        "# Plot ACF for the residuals\n",
        "plt.figure(figsize=(8, 6))\n",
        "plot_acf(residuals.dropna(), lags=40, title=\"ACF of Residuals\")\n",
        "plt.show()\n",
        "\n",
        "# Plot PACF for the residuals\n",
        "plt.figure(figsize=(8, 6))\n",
        "plot_pacf(residuals.dropna(), lags=40, title=\"PACF of Residuals\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "evh5VCUyssb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the ARIMA model\n",
        "arima_model = ARIMA(train['cnt'], order=(1, 1, 1))\n",
        "arima_result = arima_model.fit()\n",
        "\n",
        "# Residual analysis for manually tuned ARIMA\n",
        "arima_residuals = arima_result.resid\n",
        "\n",
        "# Plot residuals\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(arima_residuals, label=\"ARIMA Residuals\", color= \"blue\")\n",
        "plt.axhline(0, linestyle=\"--\", color=\"red\", linewidth=1)\n",
        "plt.title(\"ARIMA Residual Analysis\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ACF of ARIMA residuals\n",
        "plt.figure(figsize=(8, 6))\n",
        "plot_acf(arima_residuals.dropna(), lags=40)\n",
        "plt.title(\"ACF of ARIMA Residuals\")\n",
        "plt.xlabel(\"Lags\")\n",
        "plt.ylabel(\"Autocorrelation\")\n",
        "plt.show()\n",
        "\n",
        "# Histogram of Residuals\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(arima_residuals, kde=True, color=\"purple\")\n",
        "plt.title(\"Histogram of Residuals - ARIMA Model\")\n",
        "plt.xlabel(\"Residuals\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.axvline(0, linestyle=\"--\", color=\"red\", linewidth=1)\n",
        "plt.show()\n",
        "\n",
        "# Normal Q-Q Plot for Residuals\n",
        "sm.qqplot(arima_residuals, line=\"s\", color=\"green\")\n",
        "plt.title(\"Q-Q Plot of Residuals - ARIMA Model\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uv1PiQE7vC2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 1: ETS (Exponential Smoothing)**"
      ],
      "metadata": {
        "id": "-L_Sitl0lZe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit ETS Model\n",
        "ets_model = ExponentialSmoothing(train['cnt'], seasonal='add', trend='add', seasonal_periods=12).fit()\n",
        "\n",
        "# Forecast\n",
        "ets_forecast = ets_model.forecast(len(test))\n",
        "\n",
        "# Evaluate ETS model\n",
        "ets_mse = mean_squared_error(test['cnt'], ets_forecast)\n",
        "print(f\"ETS - MSE: {ets_mse:.2f}, MAE: {ets_mae:.2f}\")"
      ],
      "metadata": {
        "id": "XhcTtVYhlXzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 2: TSLM (Time Series Linear Model)**"
      ],
      "metadata": {
        "id": "mfrvW2RPmJ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Time as a feature\n",
        "train['time'] = range(len(train))\n",
        "test['time'] = range(len(train), len(train) + len(test))\n",
        "\n",
        "# Create Polynomial Features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "train_features = poly.fit_transform(train[['time']])\n",
        "test_features = poly.transform(test[['time']])\n",
        "\n",
        "# Fit Linear Model\n",
        "tslm_model = LinearRegression()\n",
        "tslm_model.fit(train_features, train['cnt'])\n",
        "\n",
        "# Forecast\n",
        "tslm_forecast = tslm_model.predict(test_features)\n",
        "\n",
        "# Evaluate TSLM\n",
        "tslm_mse = mean_squared_error(test['cnt'], tslm_forecast)\n",
        "tslm_mae = mean_absolute_error(test['cnt'], tslm_forecast)\n",
        "print(f\"TSLM - MSE: {tslm_mse:.2f}, MAE: {tslm_mae:.2f}\")"
      ],
      "metadata": {
        "id": "Z5b1OqmUmVhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 3: NNETAR (Neural Network Autoregression)**"
      ],
      "metadata": {
        "id": "1cJa2PNNmtUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n",
        "\n",
        "# Prepare data for Neural Network\n",
        "lag = 12  # Number of lags\n",
        "X_train = np.array([train['cnt'].iloc[i - lag:i].values for i in range(lag, len(train))])\n",
        "y_train = train['cnt'].iloc[lag:].values\n",
        "\n",
        "# Build NNETAR model\n",
        "nnetar_model = Sequential()\n",
        "nnetar_model.add(Dense(32, activation='relu', input_shape=(lag,)))\n",
        "nnetar_model.add(Dense(16, activation='relu'))\n",
        "nnetar_model.add(Dense(1))\n",
        "nnetar_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train NNETAR model\n",
        "nnetar_model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
        "\n",
        "# Forecast with NNETAR\n",
        "X_test = np.array([test['cnt'].iloc[i - lag:i].values for i in range(lag, len(test))])\n",
        "nnetar_forecast = nnetar_model.predict(X_test)\n",
        "\n",
        "# Evaluate NNETAR\n",
        "nnetar_mse = mean_squared_error(test['cnt'][lag:], nnetar_forecast)\n",
        "nnetar_mae = mean_absolute_error(test['cnt'][lag:], nnetar_forecast)\n",
        "print(f\"NNETAR - MSE: {nnetar_mse:.2f}, MAE: {nnetar_mae:.2f}\")"
      ],
      "metadata": {
        "id": "4YYXoqm0myII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 4: ARIMA**"
      ],
      "metadata": {
        "id": "Ll_4ZmLNnRjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ARIMA model with manually specified parameters\n",
        "arima_model = ARIMA(train['cnt'], order=(1, 1, 1))\n",
        "arima_result = arima_model.fit()\n",
        "\n",
        "# Forecast using ARIMA\n",
        "arima_forecast = arima_result.forecast(steps=len(test))\n",
        "\n",
        "# Evaluate ARIMA\n",
        "arima_mse = mean_squared_error(test['cnt'], arima_forecast)\n",
        "arima_mae = mean_absolute_error(test['cnt'], arima_forecast)\n",
        "print(f\"ARIMA Model - MSE: {arima_mse:.2f}, MAE: {arima_mae:.2f}\")"
      ],
      "metadata": {
        "id": "uTTpimOEmNFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ARIMA forecast vs. actual\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(test.index, test['cnt'], label=\"Actual\")\n",
        "plt.plot(test.index, arima_forecast, label=\"ARIMA Forecast\", linestyle=\"--\")\n",
        "plt.legend()\n",
        "plt.title(\"ARIMA Forecast vs Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cRnONvLdqqMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 5: Auto-ARIMA (SARIMA with Automated Parameter Selection)**"
      ],
      "metadata": {
        "id": "eXGZMObroctd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find optimal parameters using Auto-ARIMA\n",
        "auto_model = pm.auto_arima(train['cnt'], seasonal=True, m=12, suppress_warnings=True, stepwise=True)\n",
        "\n",
        "print(auto_model.summary())\n",
        "\n",
        "# Extract the optimal parameters\n",
        "auto_order = auto_model.order\n",
        "auto_seasonal_order = auto_model.seasonal_order\n",
        "\n",
        "# Train SARIMA with Auto-ARIMA parameters\n",
        "sarima_model = SARIMAX(train['cnt'], order=auto_order, seasonal_order=auto_seasonal_order)\n",
        "sarima_result = sarima_model.fit()\n",
        "\n",
        "# Forecast using Auto-ARIMA\n",
        "sarima_forecast = sarima_result.predict(start=test.index[0], end=test.index[-1])\n",
        "\n",
        "# Evaluate Auto-ARIMA\n",
        "sarima_mse = mean_squared_error(test['cnt'], sarima_forecast)\n",
        "sarima_mae = mean_absolute_error(test['cnt'], sarima_forecast)\n",
        "\n",
        "print(f\"Auto-ARIMA Model - MSE: {sarima_mse:.2f}, MAE: {sarima_mae:.2f}\")"
      ],
      "metadata": {
        "id": "y9E42vHOoepW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Auto-ARIMA forecast vs. actual\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(test.index, test['cnt'], label=\"Actual\")\n",
        "plt.plot(test.index, sarima_forecast, label=\"Auto-ARIMA Forecast\", linestyle=\"--\")\n",
        "plt.legend()\n",
        "plt.title(\"Auto-ARIMA (SARIMA) Forecast vs Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uB3ShJqNpxFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualization of Results**"
      ],
      "metadata": {
        "id": "CzRLKF85rriu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot all forecasts\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train['cnt'], label='Train')\n",
        "plt.plot(test['cnt'], label='Test')\n",
        "plt.plot(test.index, ets_forecast, label='ETS Forecast', linestyle='--')\n",
        "plt.plot(test.index, tslm_forecast, label='TSLM Forecast', linestyle=':')\n",
        "plt.plot(test.index[lag:], nnetar_forecast, label='NNETAR Forecast', linestyle='-.')\n",
        "plt.plot(test.index, arima_forecast, label='ARIMA Forecast', linestyle='-')\n",
        "plt.plot(test.index, sarima_forecast, label='Auto-ARIMA Forecast', linestyle='--')\n",
        "plt.legend()\n",
        "plt.title('Model Forecasts')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ioOZkWwnqGbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary Table**"
      ],
      "metadata": {
        "id": "CUtGV7gdvaha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics for all models (use the values from your analysis)\n",
        "summary_data = {\n",
        "    \"Model\": [\"ETS\", \"TSLM\", \"NNETAR\", \"ARIMA\", \"Auto-ARIMA\"],\n",
        "    \"Mean Squared Error (MSE)\": [ets_mse, tslm_mse, nnetar_mse, arima_mse, sarima_mse],\n",
        "    \"Mean Absolute Error (MAE)\": [ets_mae, tslm_mae, nnetar_mae, arima_mae, sarima_mae],\n",
        "    \"Remarks\": [\n",
        "        \"Captured seasonality well.\",\n",
        "        \"Overfitted to data trends.\",\n",
        "        \"Best performance with non-linearity.\",\n",
        "        \"Performed adequately for time series.\",\n",
        "        \"Streamlined parameter tuning but similar to ARIMA.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convert the data to a DataFrame\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "display(summary_df)"
      ],
      "metadata": {
        "id": "Zi0zj8FuvWpP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}